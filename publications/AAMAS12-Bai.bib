@InProceedings{AAMAS12-Bai,
  author = {Aijun Bai and Feng Wu and Xiaoping Chen},
  title = {Online Planning for Large MDPs with MAXQ Decomposition (Extended Abstract)},
  booktitle = {Proc. of 11th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2012)},
  location = {Valencia, Spain},
  month = {June},
  year = {2012},
  abstract = {Markov decision processes (MDPs) provide an expressive
  framework for planning in stochastic domains. However,
  exactly solving a large MDP is often intractable due to the
  curse of dimensionality. Online algorithms help overcome
  the high computational complexity by avoiding computing
  a policy for each possible state. Hierarchical decomposition
  is another promising way to help scale MDP algorithms up
  to large domains by exploiting their underlying structure. In
  this paper, we present an effort on combining the benefits of
  a general hierarchical structure based on MAXQ value 
  function decomposition with the power of heuristic and approx-
  imate techniques for developing an online planning 
  framework, called MAXQ-OP. The proposed framework provides
  a principled approach for programming autonomous agents
  in a large stochastic domain. We have been conducting a
  long-term case-study with the RoboCup soccer simulation
  2D domain, which is extremely larger than domains 
  usually studied in literature, as the major benchmark to this
  research. The case-study showed that the agents developed
  with this framework and the related techniques reached out-
  standing performances, showing its high scalability to very
  large domains.
  },
}
